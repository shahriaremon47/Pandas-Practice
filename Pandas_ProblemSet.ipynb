{
 "cells": [
  {
   "cell_type": "raw",
   "id": "292112d5-af19-421e-a5ff-4e84b3c35237",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf437e5e-1384-40b5-89a8-45592bb3b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date         Product_Name  Revenue  Quantity\n",
      "0 2023-01-15    Pro-Gaming Laptop   1500.0       1.0\n",
      "1 2023-02-12       Wireless Mouse     25.5      10.0\n",
      "2 2023-03-15  Mechanical Keyboard    120.0       1.5\n",
      "3 2023-04-20       Gaming Monitor      NaN       2.0\n",
      "4 2023-05-05    Pro-Gaming Laptop   1500.0       1.0\n",
      "\n",
      "Types:\n",
      "Date            datetime64[ns]\n",
      "Product_Name            object\n",
      "Revenue                float64\n",
      "Quantity               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. SETUP\n",
    "raw_data = {\n",
    "    'Date': ['2023-01-15', '2023/02/12', '15-03-2023', '2023-04-20', '2023-05-05'],\n",
    "    'Product_Name': ['  PRO-Gaming Laptop  ', 'wireless mouse', 'Mechanical KEYBOARD', 'Gaming monitor', '  PRO-Gaming Laptop  '],\n",
    "    'Revenue': ['$1,500.00', '$25.50', '$120.00', 'Invalid', '$1,500.00'],\n",
    "    'Quantity': [1, 10, np.nan, 2, 1]\n",
    "}\n",
    "df = pd.DataFrame(raw_data)\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: Clean Revenue\n",
    "# Remove symbols and convert to numeric, turning \"Invalid\" into NaN\n",
    "df['Revenue'] = df['Revenue'].str.replace(r'[$,]', '', regex=True)\n",
    "df['Revenue'] = pd.to_numeric(df['Revenue'], errors='coerce')\n",
    "\n",
    "# Task 2: Fix Date (UPDATED LINE)\n",
    "# Added format='mixed' so it handles both / and - separators\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)\n",
    "\n",
    "# Task 3: Standardize Product_Name\n",
    "df['Product_Name'] = df['Product_Name'].str.strip().str.title()\n",
    "\n",
    "# Task 4: Handle Missing Data\n",
    "median_qty = df['Quantity'].median()\n",
    "df['Quantity'] = df['Quantity'].fillna(median_qty)\n",
    "\n",
    "print(df)\n",
    "print(\"\\nTypes:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a94aac-c39d-4b7b-b11f-70caac058635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1: High Performers ---\n",
      "      Name Department  Salary  Years_Experience  Performance_Rating\n",
      "0    Alice         HR   60000                 5                 4.2\n",
      "2  Charlie         IT   92000                12                 4.5\n",
      "4      Eva      Sales   88000                10                 4.9\n",
      "6    Grace  Marketing  105000                15                 4.8\n",
      "\n",
      "--- Task 2: IT Team Budget ---\n",
      "      Name  Salary\n",
      "1      Bob   85000\n",
      "2  Charlie   92000\n",
      "5    Frank   72000\n",
      "\n",
      "--- Task 3: Highest Paid Employee ---\n",
      "    Name Department\n",
      "6  Grace  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace'],\n",
    "    'Department': ['HR', 'IT', 'IT', 'Sales', 'Sales', 'IT', 'Marketing'],\n",
    "    'Salary': [60000, 85000, 92000, 45000, 88000, 72000, 105000],\n",
    "    'Years_Experience': [5, 8, 12, 1, 10, 3, 15],\n",
    "    'Performance_Rating': [4.2, 3.8, 4.5, 3.0, 4.9, 4.0, 4.8]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: High Performers\n",
    "# LOGIC: Use '&' for AND. You MUST wrap each condition in parentheses ().\n",
    "# Python gets confused by the order of operations without them.\n",
    "top_performers = df[(df['Performance_Rating'] > 4.0) & (df['Years_Experience'] >= 5)]\n",
    "\n",
    "print(\"--- Task 1: High Performers ---\")\n",
    "print(top_performers)\n",
    "\n",
    "\n",
    "# Task 2: The IT Budget\n",
    "# LOGIC: We use .loc[rows, columns].\n",
    "# Rows = where Department is IT. Columns = Name and Salary.\n",
    "it_team = df.loc[df['Department'] == 'IT', ['Name', 'Salary']]\n",
    "\n",
    "print(\"\\n--- Task 2: IT Team Budget ---\")\n",
    "print(it_team)\n",
    "\n",
    "\n",
    "# Task 3: The Outlier\n",
    "# LOGIC: First find the max salary value, then filter the dataframe for that value.\n",
    "# (Alternative: You could use .nlargest(1, 'Salary') as a shortcut)\n",
    "highest_paid = df[df['Salary'] == df['Salary'].max()]\n",
    "\n",
    "# Extracting just the columns we asked for\n",
    "result = highest_paid[['Name', 'Department']]\n",
    "\n",
    "print(\"\\n--- Task 3: Highest Paid Employee ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cdb87a5-e543-4476-9fa4-e83edbb519b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student  Exam_1  Exam_2  Participation  Final_Score Status Grade\n",
      "0    Emma      85      90             10         98.0   Pass     A\n",
      "1    Liam      55      60              5         63.0   Pass     C\n",
      "2  Olivia      90      95             10        103.0   Pass     A\n",
      "3    Noah      70      75              8         81.0   Pass     B\n",
      "4     Ava      40      50              2         48.0   Fail     C\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. SETUP\n",
    "data = {\n",
    "    'Student': ['Emma', 'Liam', 'Olivia', 'Noah', 'Ava'],\n",
    "    'Exam_1': [85, 55, 90, 70, 40],\n",
    "    'Exam_2': [90, 60, 95, 75, 50],\n",
    "    'Participation': [10, 5, 10, 8, 2] \n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: The Weighted Score (Vectorization)\n",
    "# LOGIC: Pandas allows you to do math on whole columns at once. \n",
    "# It aligns the rows automatically. This is much faster than a loop.\n",
    "df['Final_Score'] = (df['Exam_1'] * 0.4) + (df['Exam_2'] * 0.6) + df['Participation']\n",
    "\n",
    "\n",
    "# Task 2: Binary Logic (np.where)\n",
    "# LOGIC: np.where(condition, value_if_true, value_if_false)\n",
    "# This is the \"Excel IF statement\" of Python. Extremely fast.\n",
    "df['Status'] = np.where(df['Final_Score'] >= 60, 'Pass', 'Fail')\n",
    "\n",
    "\n",
    "# Task 3: Complex Logic (Apply)\n",
    "# LOGIC: When logic is too complex for one line, write a normal Python function\n",
    "# and \"apply\" it to the column.\n",
    "\n",
    "def get_grade(score):\n",
    "    if score >= 90:\n",
    "        return 'A'\n",
    "    elif score >= 80:\n",
    "        return 'B'\n",
    "    else:\n",
    "        return 'C'\n",
    "\n",
    "# Applying the function to every row in 'Final_Score'\n",
    "df['Grade'] = df['Final_Score'].apply(get_grade)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e558eb4b-745d-4b45-bbb3-6abc89dff914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1: Total Sales by Region ---\n",
      "Region\n",
      "East     1300\n",
      "North    4200\n",
      "South    4500\n",
      "Name: Sales, dtype: int64\n",
      "\n",
      "--- Task 2: Average Revenue per Product Transaction ---\n",
      "Product\n",
      "Gadget    1933.333333\n",
      "Widget    1050.000000\n",
      "Name: Sales, dtype: float64\n",
      "\n",
      "--- Task 3: Executive Summary ---\n",
      "        Total Revenue  Transaction Count\n",
      "Region                                  \n",
      "East             1300                  2\n",
      "North            4200                  3\n",
      "South            4500                  2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP\n",
    "data = {\n",
    "    'Region': ['North', 'South', 'North', 'East', 'South', 'North', 'East'],\n",
    "    'Product': ['Widget', 'Widget', 'Gadget', 'Widget', 'Gadget', 'Widget', 'Gadget'],\n",
    "    'Sales': [1000, 1500, 2000, 500, 3000, 1200, 800],\n",
    "    'Quantity': [5, 10, 8, 2, 15, 6, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: Sales by Region\n",
    "# LOGIC: Group by 'Region', select the 'Sales' column, and Sum it.\n",
    "# This produces a Series indexed by Region.\n",
    "region_sales = df.groupby('Region')['Sales'].sum()\n",
    "\n",
    "print(\"--- Task 1: Total Sales by Region ---\")\n",
    "print(region_sales)\n",
    "\n",
    "\n",
    "# Task 2: Product Performance\n",
    "# LOGIC: Group by 'Product', select 'Sales', and calculate the Mean (Average).\n",
    "product_avg = df.groupby('Product')['Sales'].mean()\n",
    "\n",
    "print(\"\\n--- Task 2: Average Revenue per Product Transaction ---\")\n",
    "print(product_avg)\n",
    "\n",
    "\n",
    "# Task 3: The Executive Report (Multi-Agg)\n",
    "# LOGIC: Use .agg() to pass a list of functions. \n",
    "# We want the Sum of sales and the Count of transactions (rows) per region.\n",
    "executive_report = df.groupby('Region')['Sales'].agg(['sum', 'count'])\n",
    "\n",
    "# Optional: Rename columns for a prettier report\n",
    "executive_report = executive_report.rename(columns={'sum': 'Total Revenue', 'count': 'Transaction Count'})\n",
    "\n",
    "print(\"\\n--- Task 3: Executive Summary ---\")\n",
    "print(executive_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04740d74-3c9c-4b98-b9b0-a2a6270e663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1: Merged Data ---\n",
      "   User_ID     Name  Order_ID  Amount\n",
      "0      101    Alice       2.0   500.0\n",
      "1      101    Alice       4.0   300.0\n",
      "2      102      Bob       NaN     NaN\n",
      "3      103  Charlie       1.0   250.0\n",
      "4      103  Charlie       3.0   100.0\n",
      "5      104    David       NaN     NaN\n",
      "\n",
      "--- Task 2: Total Spending per User ---\n",
      "Name\n",
      "Alice      800.0\n",
      "Bob          0.0\n",
      "Charlie    350.0\n",
      "David        0.0\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "--- Task 3: Users with Zero Orders ---\n",
      "    Name\n",
      "2    Bob\n",
      "5  David\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP\n",
    "users = pd.DataFrame({\n",
    "    'User_ID': [101, 102, 103, 104],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David']\n",
    "})\n",
    "\n",
    "orders = pd.DataFrame({\n",
    "    'Order_ID': [1, 2, 3, 4],\n",
    "    'User_ID': [103, 101, 103, 101], \n",
    "    'Amount': [250, 500, 100, 300]\n",
    "})\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: The \"Big Picture\" (Left Join)\n",
    "# LOGIC: We want to keep ALL Users (Left table), even if they have no orders.\n",
    "# 'on' specifies the common column (Key). 'how' specifies the join type.\n",
    "all_data = pd.merge(users, orders, on='User_ID', how='left')\n",
    "\n",
    "print(\"--- Task 1: Merged Data ---\")\n",
    "print(all_data)\n",
    "\n",
    "\n",
    "# Task 2: The \"Big Spenders\"\n",
    "# LOGIC: Now that the data is merged, we can group by Name and Sum the Amount.\n",
    "# Note: Alice and Charlie appear multiple times in 'all_data', but groupby handles that.\n",
    "spending = all_data.groupby('Name')['Amount'].sum()\n",
    "\n",
    "print(\"\\n--- Task 2: Total Spending per User ---\")\n",
    "print(spending)\n",
    "\n",
    "\n",
    "# Task 3: The \"Ghost Users\"\n",
    "# LOGIC: In a Left Join, if there is no match, Pandas fills the columns with NaN (Not a Number).\n",
    "# We filter for rows where 'Order_ID' is NaN to find users who didn't buy anything.\n",
    "ghost_users = all_data[all_data['Order_ID'].isna()]\n",
    "\n",
    "print(\"\\n--- Task 3: Users with Zero Orders ---\")\n",
    "print(ghost_users[['Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cc2e0f-75b8-4f54-9e7c-bda12c86ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1: Melted (Long) Data ---\n",
      "          City    Day  Temperature\n",
      "0     New York  Day_1           20\n",
      "1  Los Angeles  Day_1           25\n",
      "2      Chicago  Day_1           15\n",
      "3     New York  Day_2           22\n",
      "4  Los Angeles  Day_2           26\n",
      "5      Chicago  Day_2           14\n",
      "6     New York  Day_3           19\n",
      "7  Los Angeles  Day_3           24\n",
      "8      Chicago  Day_3           16\n",
      "\n",
      "--- Task 2: Pivoted (Wide) Data ---\n",
      "Day         City  Day_1  Day_2  Day_3\n",
      "0        Chicago     15     14     16\n",
      "1    Los Angeles     25     26     24\n",
      "2       New York     20     22     19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. SETUP\n",
    "data = {\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago'],\n",
    "    'Day_1': [20, 25, 15],\n",
    "    'Day_2': [22, 26, 14],\n",
    "    'Day_3': [19, 24, 16]\n",
    "}\n",
    "df_wide = pd.DataFrame(data)\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: Wide to Long (Melt)\n",
    "# LOGIC: \n",
    "# id_vars = The column(s) you want to KEEP as identifiers (City).\n",
    "# var_name = What to name the column created from the old headers (Day).\n",
    "# value_name = What to name the column created from the numbers (Temperature).\n",
    "df_long = df_wide.melt(id_vars=['City'], var_name='Day', value_name='Temperature')\n",
    "\n",
    "print(\"--- Task 1: Melted (Long) Data ---\")\n",
    "print(df_long)\n",
    "\n",
    "\n",
    "# Task 2: Long to Wide (Pivot)\n",
    "# LOGIC: This is the exact inverse of melt.\n",
    "# index = What should stay as rows? (City)\n",
    "# columns = What should become the new column headers? (Day)\n",
    "# values = What numbers fill the cells? (Temperature)\n",
    "df_pivoted = df_long.pivot(index='City', columns='Day', values='Temperature')\n",
    "\n",
    "# Optional: Reset index if you want 'City' to be a regular column again, not the index\n",
    "df_pivoted = df_pivoted.reset_index()\n",
    "\n",
    "print(\"\\n--- Task 2: Pivoted (Wide) Data ---\")\n",
    "print(df_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "969682c9-4452-48f3-afcf-76a8e3a89a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task 1: Weekly Averages ---\n",
      "            Price\n",
      "2023-01-01  100.0\n",
      "2023-01-08  105.0\n",
      "2023-01-15  116.0\n",
      "2023-01-22  115.4\n",
      "\n",
      "--- Task 2 & 3: Rolling & Shifting ---\n",
      "            Price  Rolling_Avg  Daily_Return\n",
      "2023-01-01    100          NaN           NaN\n",
      "2023-01-02    102          NaN           2.0\n",
      "2023-01-03    104   102.000000           2.0\n",
      "2023-01-04    103   103.000000          -1.0\n",
      "2023-01-05    105   104.000000           2.0\n",
      "2023-01-06    107   105.000000           2.0\n",
      "2023-01-07    108   106.666667           1.0\n",
      "2023-01-08    106   107.000000          -2.0\n",
      "2023-01-09    110   108.000000           4.0\n",
      "2023-01-10    115   110.333333           5.0\n",
      "2023-01-11    114   113.000000          -1.0\n",
      "2023-01-12    116   115.000000           2.0\n",
      "2023-01-13    118   116.000000           2.0\n",
      "2023-01-14    119   117.666667           1.0\n",
      "2023-01-15    120   119.000000           1.0\n",
      "2023-01-16    122   120.333333           2.0\n",
      "2023-01-17    118   120.000000          -4.0\n",
      "2023-01-18    115   118.333333          -3.0\n",
      "2023-01-19    112   115.000000          -3.0\n",
      "2023-01-20    110   112.333333          -2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. SETUP\n",
    "dates = pd.date_range(start='2023-01-01', periods=20, freq='D')\n",
    "data = {\n",
    "    'Price': [100, 102, 104, 103, 105, 107, 108, 106, 110, 115, \n",
    "              114, 116, 118, 119, 120, 122, 118, 115, 112, 110]\n",
    "}\n",
    "df = pd.DataFrame(data, index=dates)\n",
    "\n",
    "# --- SOLUTION ---\n",
    "\n",
    "# Task 1: Weekly Averages (Resample)\n",
    "# LOGIC: 'W' stands for Weekly. This groups data by week and calculates the mean.\n",
    "# It acts like a groupby, but for time frequencies.\n",
    "weekly_df = df.resample('W').mean()\n",
    "\n",
    "print(\"--- Task 1: Weekly Averages ---\")\n",
    "print(weekly_df)\n",
    "\n",
    "\n",
    "# Task 2: Smoothing Trends (Rolling)\n",
    "# LOGIC: This takes a window of 3 rows, calculates the mean, and slides down.\n",
    "# The first two rows will be NaN because there isn't enough data yet (need 3 points).\n",
    "df['Rolling_Avg'] = df['Price'].rolling(window=3).mean()\n",
    "\n",
    "\n",
    "# Task 3: Daily Change (Shift)\n",
    "# LOGIC: .shift(1) moves the entire column down by 1 row.\n",
    "# Price (Today) - Price (Yesterday) = Daily Change\n",
    "df['Daily_Return'] = df['Price'] - df['Price'].shift(1)\n",
    "\n",
    "print(\"\\n--- Task 2 & 3: Rolling & Shifting ---\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb65e80-3aea-4995-af0d-e4c799a9caf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
